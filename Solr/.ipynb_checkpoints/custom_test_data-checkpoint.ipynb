{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id= \"1234234\"\n",
      "SELECT COUNT(*)  as count FROM t_cms_course WHERE 1=1 AND id= \"1234234\"\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import traceback\n",
    "\n",
    "\n",
    "class DBHelper:\n",
    "    def __init__(self):\n",
    "        # 链接数据库\n",
    "        try:\n",
    "            # charset 默认是 latin1, 查询到中文会是？？\n",
    "            # charset='utf8mb4' 避免有表情时插入错误\n",
    "            self.__db = pymysql.connect(\n",
    "                host='127.0.0.1',\n",
    "                user='root',\n",
    "                password='111111',\n",
    "                database='course',\n",
    "                charset='utf8mb4')\n",
    "            self.__cur = self.__db.cursor()\n",
    "        except pymysql.Error as e:\n",
    "            print('链接数据库失败：', traceback.print_exc())\n",
    "\n",
    "    def insert(self, table, myDict):\n",
    "        # 插入一条数据\n",
    "        try:\n",
    "            cols = ','.join(myDict.keys())\n",
    "            values = ','.join(\n",
    "                map(lambda x: '\"' + str(x) + '\"', myDict.values()))\n",
    "            sql = 'INSERT INTO %s (%s) VALUES (%s)' % (table, cols, values)\n",
    "            result = self.__cur.execute(sql)\n",
    "            self.__db.commit()\n",
    "        except pymysql.Error as e:\n",
    "            print('插入失败：', traceback.print_exc())\n",
    "            # 发生错误时回滚\n",
    "            # DML 语句，执行完之后，处理的数据，都会放在回滚段中（除了 SELECT 语句），\n",
    "            # 等待用户进行提交（COMMIT）或者回滚 （ROLLBACK），当用户执行 COMMIT / ROLLBACK后，\n",
    "            # 放在回滚段中的数据就会被删除。\n",
    "            self.__db.rollback()\n",
    "\n",
    "    def query(self, sql):\n",
    "        try:\n",
    "            self.__cur.execute(sql)\n",
    "            result = self.__cur.fetchall()\n",
    "            self.__db.commit()\n",
    "            if result:\n",
    "                return result\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "        except pymysql.Error as e:\n",
    "            print(\"数据库-查询异常\", traceback.print_exc())\n",
    "\n",
    "    '''\n",
    "    查询数据库中是否已经存在record\n",
    "    '''\n",
    "\n",
    "    def check_exist(self, table, my_dict):\n",
    "        try:\n",
    "            if not len(my_dict):\n",
    "                return\n",
    "            values = ' AND '.join(\n",
    "                map(lambda x: str(x) + '= \"' + str(my_dict[x]) + '\"', my_dict.keys()))\n",
    "            print(values)\n",
    "            sql = 'SELECT COUNT(*)  as count FROM %s WHERE 1=1 AND %s' % (table, values)\n",
    "            print(sql)\n",
    "            self.__cur.execute(sql)\n",
    "            results = self.__cur.fetchall();\n",
    "            if results[0][0] > 0:\n",
    "                    return True\n",
    "            else:\n",
    "                    return False\n",
    "               \n",
    "        except pymysql.Error as e:\n",
    "            print('查询失败！', traceback.print_exc())\n",
    "            return False\n",
    "\n",
    "    def close(self):\n",
    "        self.__cur.close()\n",
    "        self.__db.close()\n",
    "\n",
    "\n",
    "dbhelpser = DBHelper()\n",
    "my_dict = {'id': '1234234'}\n",
    "print(dbhelpser.check_exist('t_cms_course', my_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 课程测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"rows\":{\"coursetemplate\":\"\",\"courseisinorder\":\"1\",\"coursecategory\":\"1100000000000000109\",\"courseget\":\"\",\"courseisdisplay\":\"1\",\"courseserializestate\":\"\",\"courseprepare\":\"\",\"coursevideo\":\"\",\"coursefitobj\":\"\",\"coursetype\":\"\",\"operatetime\":\"2017-02-17 20:07:06\",\"sourcesign\":\"\",\"coursesubjects\":\"\",\"id\":\"1100000000000005706\",\"languageList\":[],\"coursecredit\":6,\"delflag\":\"U\",\"operatercode\":\"2000244711\",\"courseaddress\":\"\",\"creatertime\":\"2017-02-17 19:58:39\",\"coursename\":\"不要动这个333\",\"extend_6\":\"\",\"courseintro\":\"不要动这个8\",\"extend_5\":\"\",\"courseproducer\":\"\",\"coursestate\":\"01\",\"ownerorg\":\"1100000000000000746\",\"tagList\":[{\"ownerorg\":\"1100000000000000746\",\"operatercode\":\"2000244711\",\"creatertime\":\"2017-02-17 19:58:49\",\"versions\":\"2648\",\"tagid\":\"1100000000000000206\",\"operatetime\":\"2017-02-17 19:58:49\",\"tagdescn\":\"不要动这个1\",\"id\":\"1100000000000007348\",\"sort\":1,\"creatercode\":\"2000244711\",\"delflag\":\"A\",\"courseid\":\"1100000000000005706\"},{\"ownerorg\":\"1100000000000000746\",\"operatercode\":\"2000244711\",\"creatertime\":\"2017-02-17 19:58:57\",\"versions\":\"2649\",\"tagid\":\"1100000000000000270\",\"operatetime\":\"2017-02-17 19:58:57\",\"tagdescn\":\"不要动这个2\",\"id\":\"1100000000000007349\",\"sort\":2,\"creatercode\":\"2000244711\",\"delflag\":\"A\",\"courseid\":\"1100000000000005706\"}],\"courseprice\":\"\",\"versions\":\"4848\",\"extend_4\":\"\",\"extend_3\":\"\",\"extend_2\":\"\",\"extend_1\":\"\",\"creatercode\":\"2000244711\",\"courseupperlimit\":20,\"courseid\":\"1100000000000005706\",\"courseoutsideurl\":\"\",\"courseclassify\":\"0\",\"coursecover\":\"6666666336666\"},\"msgCode\":\"1\",\"isSuccess\":\"true\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def push_doc(course_id):\n",
    "    r  = requests.get(\"http://localhost:8080/history-web/search/pushDoc?courseId=\" + course_id)\n",
    "    print(r.text)\n",
    "\n",
    "push_doc(\"1100000000000005706\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小说\n",
      "港台\n",
      "外国文学\n",
      "港台\n",
      "文学\n",
      "港台\n",
      "随笔\n",
      "港台\n",
      "中国文学\n",
      "港台\n",
      "经典\n",
      "港台\n",
      "日本文学\n",
      "港台\n",
      "散文\n",
      "港台\n",
      "村上春树\n",
      "港台\n",
      "诗歌\n",
      "港台\n",
      "童话\n",
      "港台\n",
      "儿童文学\n",
      "港台\n",
      "古典文学\n",
      "港台\n",
      "王小波\n",
      "港台\n",
      "杂文\n",
      "港台\n",
      "名著\n",
      "港台\n",
      "余华\n",
      "港台\n",
      "张爱玲\n",
      "港台\n",
      "当代文学\n",
      "港台\n",
      "钱钟书\n",
      "港台\n",
      "外国名著\n",
      "港台\n",
      "鲁迅\n",
      "港台\n",
      "诗词\n",
      "港台\n",
      "茨威格\n",
      "港台\n",
      "米兰·昆德拉\n",
      "港台\n",
      "杜拉斯\n",
      "港台\n",
      "港台\n",
      "港台\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "r = requests.get(\"https://book.douban.com/tag/?view=type&icn=index-sorttags-all\");\n",
    "dbhelper = DBHelper()\n",
    "soup  = BeautifulSoup(r.text, \"html.parser\")\n",
    "tags = soup.find(\"table\",{\"class\",\"tagCol\"}).findAll(\"a\")\n",
    "lentag = []\n",
    "for a in tags:\n",
    "    lentag.append(a.text)\n",
    "for i in range(len(lentag)):\n",
    "    print(lentag[i])\n",
    "    myDict = {\n",
    "        \"id\": 1100000000000000270 + i,\n",
    "        \"courseid\": 1,\n",
    "        \"parentid\":1100000000000000001,\n",
    "        \"catalogtype\":\"1\",\n",
    "        \"catalogname\":lentag[i],\n",
    "        \"delflag\":\"A\"\n",
    "    }\n",
    "    dbhelper.insert(\"t_cms_course_catalog\",myDict)\n",
    "    print(a.text)\n",
    "#print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "headers={'content-type': 'application/json'}\n",
    "    \n",
    "def book_info(pub_info):\n",
    "    if len(pub_info) > 4:\n",
    "        if \"[\" in pub_info[0].strip():\n",
    "            return pub_info[0].strip().split(\" \")[0],pub_info[0].strip().split(\" \")[1],pub_info[1].strip(),pub_info[2].strip(),pub_info[3].strip(),pub_info[4].strip()\n",
    "        else:\n",
    "            return \"中\",pub_info[0].strip(),pub_info[1].strip(),pub_info[2].strip(),pub_info[3].strip(),pub_info[4].strip()\n",
    "    else:\n",
    "         if \"[\" in pub_info[0].strip():\n",
    "            return pub_info[0].strip().split(\" \")[0],pub_info[0].strip().split(\" \")[1],pub_info[1].strip(),pub_info[2].strip(),pub_info[3].strip(),\"9999元\"\n",
    "         else:\n",
    "            return \"中\",pub_info[0].strip(),pub_info[1].strip(),pub_info[2].strip(),pub_info[3].strip(),\"9999元\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def  make_req(payload):\n",
    "    r = requests.post(\"http://localhost:8080/history-web/search/doc\",data=json.dumps(payload),headers=headers)\n",
    "    print(r.text)\n",
    "    \n",
    "\n",
    "r = requests.get(\"https://book.douban.com/tag/%E5%B0%8F%E8%AF%B4\")\n",
    "soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "books = soup.find(\"ul\",{\"class\",\"subject-list\"}).findAll(\"li\")\n",
    "for i,book in enumerate(books):\n",
    "    linksoup = BeautifulSoup(str(book),\"html.parser\").find(\"div\",{\"class\",\"pic\"})\n",
    "    infosoup = BeautifulSoup(str(book),\"html.parser\").find(\"div\",{\"class\",\"info\"})    \n",
    "    book_title = BeautifulSoup(str(infosoup),\"html.parser\").find(\"a\").attrs[\"title\"]\n",
    "    print(book_title)\n",
    "    book_pic = BeautifulSoup(str(linksoup),\"html.parser\").find(\"img\").attrs[\"src\"]\n",
    "    #print(book_pic)\n",
    "    book_link = BeautifulSoup(str(linksoup),\"html.parser\").find(\"a\").attrs[\"href\"]\n",
    "    #print(book_link)\n",
    "    pub_info = str(BeautifulSoup(str(infosoup),\"html.parser\").find(\"div\",{\"class\",\"pub\"}).text).split(\"/\")    \n",
    "    #print(pub_info[0].strip(), pub_info[1].strip(),pub_info[2].strip(), pub_info[3].strip())    \n",
    "    rating_info = BeautifulSoup(str(infosoup),\"html.parser\").find(\"span\",{\"class\",\"rating_nums\"}).text\n",
    "    #print(rating_info)\n",
    "    book_intro = BeautifulSoup(str(infosoup),\"html.parser\").find(\"p\").text\n",
    "    pl_info = BeautifulSoup(str(infosoup),\"html.parser\").find(\"span\",{\"class\",\"pl\"}).text\n",
    "    #print(book_intro)\n",
    "    #print(re.findall(\"\\d+\",str(pl_info))[0])\n",
    "    pub_info = book_info(pub_info)\n",
    "    print(pub_info)\n",
    "    payload ={\n",
    "            \"id\":\"book00000\" + str(i),\n",
    "            \"coursename\":book_title,\n",
    "            \"coursetype\":\"00\",\n",
    "            \"coursestarttime\":str(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())),\n",
    "            \"courseendtime\":\"2018-12-12 11:23:33\",\n",
    "            \"coursecover\":book_pic,\n",
    "            \"courseintro\":book_intro,\n",
    "            \"coursestate\":\"00\",\n",
    "            \"courseprice\":re.findall(\"\\d+\",str(pub_info[5]).strip())[0],\n",
    "            \"catalogsort\":i,\n",
    "            \"catalogintro\":\"小说\",\n",
    "            \"catalogstarttime\":str(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())),\n",
    "            \"catalogendtime\":\"2018-11-11 12:33:33\",\n",
    "            \"catalogperiodtype\":\"A\",\n",
    "            \"catalogtimelength\": str(i *2),\n",
    "            \"catalogid\":[\"1234234\",\"23423424\",\"234234243\"],\n",
    "            \"catalogname\":[\"小说\"],\n",
    "            \"tagid\":\"t214234243\",\n",
    "            \"tagdescn\":[pub_info[0],pub_info[1],pub_info[2],\"小说\"],\n",
    "            \"teacherid\":\"t242342424\" +  str(i),\n",
    "            \"teachername\": pub_info[1],\n",
    "            \"teacherintro\":pub_info[1]\n",
    "        }\n",
    "    make_req(payload)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取详细信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "proxies = {\"http\":\"113.89.55.42:9999\"}\n",
    "headers = {\n",
    "        'User-Agent': \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6\",\n",
    "        'Accept': \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "        'Accept-Encoding': 'gzip',\n",
    "    }\n",
    "def  book_detail (book_link):\n",
    "    book_detail_resp = requests.get(book_link, proxies=proxies, headers=headers,timeout = 30)\n",
    "    book_detail_soup = BeautifulSoup(book_detail_resp.text, \"html.parser\")\n",
    "    book_tag_soup = book_detail_soup.find(\"div\",{\"class\",\"subject clearfix\"}).findAll(\"div\")\n",
    "    book_main_pic = book_tag_soup[0].find(\"a\").attrs[\"href\"]\n",
    "    #print(book_tag_soup[1])\n",
    "    book_detail_info = str(book_tag_soup[1])\n",
    "    print(book_detail_info)\n",
    "    book_info_dict = {}\n",
    "    if \"[\" in book_tag_soup[1].find(\"a\").text:\n",
    "        book_info_dict[\"author\"] = book_tag_soup[1].find(\"a\").text.split(\" \")[0].strip() + book_tag_soup[1].find(\"a\").text.split(\" \")[1].strip()\n",
    "    else:\n",
    "        book_info_dict[\"author\"] = book_tag_soup[1].find(\"a\").text.strip()\n",
    "\n",
    "\n",
    "book_detail(\"https://book.douban.com/subject/25862578/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
